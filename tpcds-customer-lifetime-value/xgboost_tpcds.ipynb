{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.snowpark\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark import version as v\n",
    "import json \n",
    "\n",
    "with open('connection.json') as f:\n",
    "    data = json.load(f)\n",
    "    USERNAME = data['user']\n",
    "    PASSWORD = data['password']\n",
    "    SF_ACCOUNT = data['account']\n",
    "    SF_WH = data['warehouse']\n",
    "\n",
    "CONNECTION_PARAMETERS = {\n",
    "   \"account\": SF_ACCOUNT,\n",
    "   \"user\": USERNAME,\n",
    "   \"password\": PASSWORD,\n",
    "}\n",
    "\n",
    "session = Session.builder.configs(CONNECTION_PARAMETERS).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='SNOWFLAKE_SAMPLE_DATA already exists, statement succeeded.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('''create database if not exists snowflake_sample_data from share sfc_samples.sample_data''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql('CREATE DATABASE IF NOT EXISTS tpcds_xgboost').collect()\n",
    "session.sql('CREATE SCHEMA IF NOT EXISTS tpcds_xgboost.demo').collect()\n",
    "session.sql(\"create or replace warehouse FE_AND_INFERENCE_WH with warehouse_size='3X-LARGE'\").collect()\n",
    "session.sql(\"create or replace warehouse snowpark_opt_wh with warehouse_size = 'MEDIUM' warehouse_type = 'SNOWPARK-OPTIMIZED'\").collect()\n",
    "session.sql(\"alter warehouse snowpark_opt_wh set max_concurrency_level = 1\").collect()\n",
    "session.use_warehouse('FE_AND_INFERENCE_WH')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select either 100 or 10 for the TPC-DS Dataset size to use below. See (https://docs.snowflake.com/en/user-guide/sample-data-tpcds.html)[here] for more information If you choose 100, I recommend >= 3XL warehouse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPCDS_SIZE_PARAM = 100\n",
    "SNOWFLAKE_SAMPLE_DB = 'SNOWFLAKE_SAMPLE_DATA' # Name of Snowflake Sample Database might be different...\n",
    "\n",
    "if TPCDS_SIZE_PARAM == 100: \n",
    "    TPCDS_SCHEMA = 'TPCDS_SF100TCL'\n",
    "elif TPCDS_SIZE_PARAM == 10:\n",
    "    TPCDS_SCHEMA = 'TPCDS_SF10TCL'\n",
    "else:\n",
    "    raise ValueError(\"Invalid TPCDS_SIZE_PARAM selection\")\n",
    "    \n",
    "store_sales = session.table(f'{SNOWFLAKE_SAMPLE_DB}.{TPCDS_SCHEMA}.store_sales')\n",
    "catalog_sales = session.table(f'{SNOWFLAKE_SAMPLE_DB}.{TPCDS_SCHEMA}.catalog_sales') \n",
    "web_sales = session.table(f'{SNOWFLAKE_SAMPLE_DB}.{TPCDS_SCHEMA}.web_sales') \n",
    "date = session.table(f'{SNOWFLAKE_SAMPLE_DB}.{TPCDS_SCHEMA}.date_dim')\n",
    "dim_stores = session.table(f'{SNOWFLAKE_SAMPLE_DB}.{TPCDS_SCHEMA}.store')\n",
    "customer = session.table(f'{SNOWFLAKE_SAMPLE_DB}.{TPCDS_SCHEMA}.customer')\n",
    "address = session.table(f'{SNOWFLAKE_SAMPLE_DB}.{TPCDS_SCHEMA}.customer_address')\n",
    "demo = session.table(f'{SNOWFLAKE_SAMPLE_DB}.{TPCDS_SCHEMA}.customer_demographics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "We will aggregate sales by customer across all channels(web, store, catalogue) and join that to customer demographic data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_sales_agged = store_sales.group_by('ss_customer_sk').agg(F.sum('ss_sales_price').as_('total_sales'))\n",
    "web_sales_agged = web_sales.group_by('ws_bill_customer_sk').agg(F.sum('ws_sales_price').as_('total_sales'))\n",
    "catalog_sales_agged = catalog_sales.group_by('cs_bill_customer_sk').agg(F.sum('cs_sales_price').as_('total_sales'))\n",
    "store_sales_agged = store_sales_agged.rename('ss_customer_sk', 'customer_sk')\n",
    "web_sales_agged = web_sales_agged.rename('ws_bill_customer_sk', 'customer_sk')\n",
    "catalog_sales_agged = catalog_sales_agged.rename('cs_bill_customer_sk', 'customer_sk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales = store_sales_agged.union_all(web_sales_agged)\n",
    "total_sales = total_sales.union_all(catalog_sales_agged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales = total_sales.group_by('customer_sk').agg(F.sum('total_sales').as_('total_sales'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = customer.select('c_customer_sk','c_current_hdemo_sk', 'c_current_addr_sk', 'c_customer_id', 'c_birth_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"CUSTOMER_SK\"  |\"C_CURRENT_HDEMO_SK\"  |\"C_CURRENT_ADDR_SK\"  |\"C_CUSTOMER_ID\"   |\"C_BIRTH_YEAR\"  |\"CA_ADDRESS_SK\"  |\"CA_ZIP\"  |\"CD_DEMO_SK\"  |\"CD_GENDER\"  |\"CD_MARITAL_STATUS\"  |\"CD_CREDIT_RATING\"  |\"CD_EDUCATION_STATUS\"  |\"CD_DEP_COUNT\"  |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|84886068       |4705                  |859249               |AAAAAAAAEDCEPAFA  |1945            |859249           |48784     |4705          |M            |D                    |Unknown             |Secondary              |0               |\n",
      "|84886701       |5003                  |49551375             |AAAAAAAANKEEPAFA  |1971            |49551375         |59391     |5003          |M            |S                    |Unknown             |2 yr Degree            |0               |\n",
      "|84887784       |2446                  |31041950             |AAAAAAAAIOIEPAFA  |1925            |31041950         |19303     |2446          |F            |D                    |Low Risk            |Unknown                |0               |\n",
      "|84887973       |5150                  |31949980             |AAAAAAAAFKJEPAFA  |1972            |31949980         |39237     |5150          |F            |U                    |Unknown             |2 yr Degree            |0               |\n",
      "|84889104       |4772                  |433342               |AAAAAAAAABOEPAFA  |1941            |433342           |60169     |4772          |F            |M                    |Unknown             |Secondary              |0               |\n",
      "|84889241       |4706                  |25345274             |AAAAAAAAJJOEPAFA  |1944            |25345274         |37752     |4706          |F            |D                    |Unknown             |Secondary              |0               |\n",
      "|84889395       |6                     |24886968             |AAAAAAAADDPEPAFA  |1930            |24886968         |83394     |6             |F            |D                    |Good                |Primary                |0               |\n",
      "|84890829       |1435                  |25496623             |AAAAAAAANMEFPAFA  |1947            |25496623         |68883     |1435          |M            |D                    |Low Risk            |2 yr Degree            |0               |\n",
      "|84891233       |4089                  |31794562             |AAAAAAAABGGFPAFA  |1976            |31794562         |25038     |4089          |M            |U                    |High Risk           |College                |0               |\n",
      "|84891316       |4703                  |20444869             |AAAAAAAAELGFPAFA  |1988            |20444869         |24536     |4703          |M            |S                    |Unknown             |Secondary              |0               |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer = customer.join(address.select('ca_address_sk', 'ca_zip'), customer['c_current_addr_sk'] == address['ca_address_sk'] )\n",
    "customer = customer.join(demo.select('cd_demo_sk', 'cd_gender', 'cd_marital_status', 'cd_credit_rating', 'cd_education_status', 'cd_dep_count'),\n",
    "                                customer['c_current_hdemo_sk'] == demo['cd_demo_sk'] )\n",
    "customer = customer.rename('c_customer_sk', 'customer_sk')\n",
    "customer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = total_sales.join(customer, on='customer_sk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.use_database('tpcds_xgboost')\n",
    "session.use_schema('demo')\n",
    "final_df.write.mode('overwrite').save_as_table('feature_store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package xgboost in the local environment is 1.7.4, which does not fit the criteria for the requirement xgboost. Your UDF might not work when the package version is different between the server and your local environment\n"
     ]
    }
   ],
   "source": [
    "session.add_packages('snowflake-snowpark-python', 'scikit-learn', 'pandas', 'numpy', 'joblib', 'cachetools', 'xgboost', 'joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Stage area ML_MODELS successfully created.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('CREATE OR REPLACE STAGE ml_models ').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "def train_model(session: snowflake.snowpark.Session) -> float:\n",
    "    snowdf = session.table(\"feature_store\")\n",
    "    snowdf = snowdf.drop(['CUSTOMER_SK', 'C_CURRENT_HDEMO_SK', 'C_CURRENT_ADDR_SK', 'C_CUSTOMER_ID', 'CA_ADDRESS_SK', 'CD_DEMO_SK'])\n",
    "    snowdf_train, snowdf_test = snowdf.random_split([0.8, 0.2], seed=82) \n",
    "\n",
    "    # save the train and test sets as time stamped tables in Snowflake \n",
    "    snowdf_train.write.mode(\"overwrite\").save_as_table(\"tpcds_xgboost.demo.tpc_TRAIN\")\n",
    "    snowdf_test.write.mode(\"overwrite\").save_as_table(\"tpcds_xgboost.demo.tpc_TEST\")\n",
    "    train_x = snowdf_train.drop(\"TOTAL_SALES\").to_pandas() # drop labels for training set\n",
    "    train_y = snowdf_train.select(\"TOTAL_SALES\").to_pandas()\n",
    "    test_x = snowdf_test.drop(\"TOTAL_SALES\").to_pandas()\n",
    "    test_y = snowdf_test.select(\"TOTAL_SALES\").to_pandas()\n",
    "    cat_cols = ['CA_ZIP', 'CD_GENDER', 'CD_MARITAL_STATUS', 'CD_CREDIT_RATING', 'CD_EDUCATION_STATUS']\n",
    "    num_cols = ['C_BIRTH_YEAR', 'CD_DEP_COUNT']\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "            ('std_scaler', StandardScaler()),\n",
    "        ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', num_pipeline, num_cols),\n",
    "                  ('encoder', OneHotEncoder(handle_unknown=\"ignore\"), cat_cols) ])\n",
    "\n",
    "    pipe = Pipeline([('preprocessor', preprocessor), \n",
    "                        ('xgboost', XGBRegressor())])\n",
    "    pipe.fit(train_x, train_y)\n",
    "\n",
    "    test_preds = pipe.predict(test_x)\n",
    "    rmse = mean_squared_error(test_y, test_preds)\n",
    "    model_file = os.path.join('/tmp', 'model.joblib')\n",
    "    joblib.dump(pipe, model_file)\n",
    "    session.file.put(model_file, \"@ml_models\",overwrite=True)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77617378801.55711"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.use_warehouse('snowpark_opt_wh')\n",
    "train_model_sp = F.sproc(train_model, session=session, replace=True, is_permanent=True, name=\"xgboost_sproc\", stage_location=\"@ml_models\")\n",
    "# Switch to Snowpark Optimized Warehouse for training and to run the stored proc\n",
    "train_model_sp(session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch back to feature engineering/inference warehouse\n",
    "session.use_warehouse('FE_AND_INFERENCE_WH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import cachetools\n",
    "import joblib\n",
    "from snowflake.snowpark import types as T\n",
    "\n",
    "session.add_import(\"@ml_models/model.joblib\")  \n",
    "\n",
    "features = [ 'C_BIRTH_YEAR', 'CA_ZIP', 'CD_GENDER', 'CD_MARITAL_STATUS', 'CD_CREDIT_RATING', 'CD_EDUCATION_STATUS', 'CD_DEP_COUNT']\n",
    "\n",
    "@cachetools.cached(cache={})\n",
    "def read_file(filename):\n",
    "       import_dir = sys._xoptions.get(\"snowflake_import_directory\")\n",
    "       if import_dir:\n",
    "              with open(os.path.join(import_dir, filename), 'rb') as file:\n",
    "                     m = joblib.load(file)\n",
    "                     return m\n",
    "\n",
    "@F.pandas_udf(session=session, max_batch_size=10000, is_permanent=True, stage_location='@ml_models', replace=True, name=\"clv_xgboost_udf\")\n",
    "def predict(df:  T.PandasDataFrame[int, str, str, str, str, str, int]) -> T.PandasSeries[float]:\n",
    "       m = read_file('model.joblib')       \n",
    "       df.columns = features\n",
    "       return m.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = session.table('feature_store')\n",
    "inference_df = inference_df.drop(['CUSTOMER_SK', 'C_CURRENT_HDEMO_SK', 'C_CURRENT_ADDR_SK', 'C_CUSTOMER_ID', 'CA_ADDRESS_SK', 'CD_DEMO_SK'])\n",
    "inputs = inference_df.drop(\"TOTAL_SALES\")\n",
    "snowdf_results = inference_df.select(*inputs,\n",
    "                    predict(*inputs).alias('PREDICTION'), \n",
    "                    (F.col('TOTAL_SALES')).alias('ACTUAL_SALES')\n",
    "                    )\n",
    "snowdf_results.write.mode('overwrite').save_as_table('predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96500091"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=snowdf_results.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_BIRTH_YEAR</th>\n",
       "      <th>CA_ZIP</th>\n",
       "      <th>CD_GENDER</th>\n",
       "      <th>CD_MARITAL_STATUS</th>\n",
       "      <th>CD_CREDIT_RATING</th>\n",
       "      <th>CD_EDUCATION_STATUS</th>\n",
       "      <th>CD_DEP_COUNT</th>\n",
       "      <th>PREDICTION</th>\n",
       "      <th>ACTUAL_SALES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1944.0</td>\n",
       "      <td>50150</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>Good</td>\n",
       "      <td>Advanced Degree</td>\n",
       "      <td>0</td>\n",
       "      <td>210252.609375</td>\n",
       "      <td>119471.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1976.0</td>\n",
       "      <td>78883</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>Good</td>\n",
       "      <td>Advanced Degree</td>\n",
       "      <td>0</td>\n",
       "      <td>210252.609375</td>\n",
       "      <td>119043.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1932.0</td>\n",
       "      <td>69310</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>Good</td>\n",
       "      <td>Advanced Degree</td>\n",
       "      <td>0</td>\n",
       "      <td>210187.984375</td>\n",
       "      <td>111926.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992.0</td>\n",
       "      <td>67683</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>Good</td>\n",
       "      <td>Advanced Degree</td>\n",
       "      <td>0</td>\n",
       "      <td>210252.609375</td>\n",
       "      <td>109641.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1944.0</td>\n",
       "      <td>42293</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>Good</td>\n",
       "      <td>Advanced Degree</td>\n",
       "      <td>0</td>\n",
       "      <td>210252.609375</td>\n",
       "      <td>106267.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_BIRTH_YEAR CA_ZIP CD_GENDER CD_MARITAL_STATUS CD_CREDIT_RATING  \\\n",
       "0        1944.0  50150         M                 W             Good   \n",
       "1        1976.0  78883         M                 W             Good   \n",
       "2        1932.0  69310         M                 W             Good   \n",
       "3        1992.0  67683         M                 W             Good   \n",
       "4        1944.0  42293         M                 W             Good   \n",
       "\n",
       "  CD_EDUCATION_STATUS  CD_DEP_COUNT     PREDICTION  ACTUAL_SALES  \n",
       "0     Advanced Degree             0  210252.609375     119471.31  \n",
       "1     Advanced Degree             0  210252.609375     119043.41  \n",
       "2     Advanced Degree             0  210187.984375     111926.28  \n",
       "3     Advanced Degree             0  210252.609375     109641.60  \n",
       "4     Advanced Degree             0  210252.609375     106267.27  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_BIRTH_YEAR</th>\n",
       "      <th>CA_ZIP</th>\n",
       "      <th>CD_GENDER</th>\n",
       "      <th>CD_MARITAL_STATUS</th>\n",
       "      <th>CD_CREDIT_RATING</th>\n",
       "      <th>CD_EDUCATION_STATUS</th>\n",
       "      <th>CD_DEP_COUNT</th>\n",
       "      <th>PREDICTION</th>\n",
       "      <th>ACTUAL_SALES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1944.0</td>\n",
       "      <td>50150</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>Good</td>\n",
       "      <td>Advanced Degree</td>\n",
       "      <td>0</td>\n",
       "      <td>210252.609375</td>\n",
       "      <td>119471.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1944.0</td>\n",
       "      <td>42293</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>Good</td>\n",
       "      <td>Advanced Degree</td>\n",
       "      <td>0</td>\n",
       "      <td>210252.609375</td>\n",
       "      <td>106267.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1944.0</td>\n",
       "      <td>13394</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>Good</td>\n",
       "      <td>2 yr Degree</td>\n",
       "      <td>0</td>\n",
       "      <td>210197.687500</td>\n",
       "      <td>121289.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1944.0</td>\n",
       "      <td>38371</td>\n",
       "      <td>F</td>\n",
       "      <td>U</td>\n",
       "      <td>Low Risk</td>\n",
       "      <td>Advanced Degree</td>\n",
       "      <td>0</td>\n",
       "      <td>210252.609375</td>\n",
       "      <td>113860.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>1944.0</td>\n",
       "      <td>59651</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>High Risk</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>210252.609375</td>\n",
       "      <td>507302.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96499805</th>\n",
       "      <td>1944.0</td>\n",
       "      <td>45258</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>Good</td>\n",
       "      <td>4 yr Degree</td>\n",
       "      <td>1</td>\n",
       "      <td>210252.609375</td>\n",
       "      <td>117063.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96499871</th>\n",
       "      <td>1944.0</td>\n",
       "      <td>33683</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2 yr Degree</td>\n",
       "      <td>0</td>\n",
       "      <td>210197.687500</td>\n",
       "      <td>114533.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96499913</th>\n",
       "      <td>1944.0</td>\n",
       "      <td>76614</td>\n",
       "      <td>F</td>\n",
       "      <td>U</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>210252.609375</td>\n",
       "      <td>117748.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96499959</th>\n",
       "      <td>1944.0</td>\n",
       "      <td>78222</td>\n",
       "      <td>F</td>\n",
       "      <td>U</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>210252.609375</td>\n",
       "      <td>108388.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96499997</th>\n",
       "      <td>1944.0</td>\n",
       "      <td>78482</td>\n",
       "      <td>F</td>\n",
       "      <td>U</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Primary</td>\n",
       "      <td>0</td>\n",
       "      <td>210252.609375</td>\n",
       "      <td>112093.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1376697 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          C_BIRTH_YEAR CA_ZIP CD_GENDER CD_MARITAL_STATUS CD_CREDIT_RATING  \\\n",
       "0               1944.0  50150         M                 W             Good   \n",
       "4               1944.0  42293         M                 W             Good   \n",
       "68              1944.0  13394         M                 M             Good   \n",
       "134             1944.0  38371         F                 U         Low Risk   \n",
       "228             1944.0  59651         M                 M        High Risk   \n",
       "...                ...    ...       ...               ...              ...   \n",
       "96499805        1944.0  45258         F                 M             Good   \n",
       "96499871        1944.0  33683         M                 M          Unknown   \n",
       "96499913        1944.0  76614         F                 U          Unknown   \n",
       "96499959        1944.0  78222         F                 U          Unknown   \n",
       "96499997        1944.0  78482         F                 U          Unknown   \n",
       "\n",
       "         CD_EDUCATION_STATUS  CD_DEP_COUNT     PREDICTION  ACTUAL_SALES  \n",
       "0            Advanced Degree             0  210252.609375     119471.31  \n",
       "4            Advanced Degree             0  210252.609375     106267.27  \n",
       "68               2 yr Degree             0  210197.687500     121289.28  \n",
       "134          Advanced Degree             0  210252.609375     113860.91  \n",
       "228                Secondary             0  210252.609375     507302.42  \n",
       "...                      ...           ...            ...           ...  \n",
       "96499805         4 yr Degree             1  210252.609375     117063.28  \n",
       "96499871         2 yr Degree             0  210197.687500     114533.88  \n",
       "96499913           Secondary             0  210252.609375     117748.83  \n",
       "96499959             Unknown             0  210252.609375     108388.53  \n",
       "96499997             Primary             0  210252.609375     112093.82  \n",
       "\n",
       "[1376697 rows x 9 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.CD_CREDIT_RATING.unique()\n",
    "res.loc[res['C_BIRTH_YEAR']==1944.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           1944.0\n",
       "1           1976.0\n",
       "2           1932.0\n",
       "3           1992.0\n",
       "4           1944.0\n",
       "             ...  \n",
       "96500086    1943.0\n",
       "96500087    1951.0\n",
       "96500088    1957.0\n",
       "96500089    1965.0\n",
       "96500090    1939.0\n",
       "Name: C_BIRTH_YEAR, Length: 96500091, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.C_BIRTH_YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96500091"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.C_BIRTH_YEAR.isnull().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res\u001b[39m.\u001b[39;49mastype({\u001b[39m'\u001b[39;49m\u001b[39mC_BIRTH_YEAR\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39mint32\u001b[39;49m\u001b[39m'\u001b[39;49m})\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\envs\\snowpark\\lib\\site-packages\\pandas\\core\\generic.py:5898\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5896\u001b[0m             res_col \u001b[39m=\u001b[39m col\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m copy \u001b[39melse\u001b[39;00m col\n\u001b[0;32m   5897\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 5898\u001b[0m             res_col \u001b[39m=\u001b[39m col\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mcdt, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   5899\u001b[0m         results\u001b[39m.\u001b[39mappend(res_col)\n\u001b[0;32m   5901\u001b[0m \u001b[39melif\u001b[39;00m is_extension_array_dtype(dtype) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   5902\u001b[0m     \u001b[39m# GH 18099/22869: columnwise conversion to extension dtype\u001b[39;00m\n\u001b[0;32m   5903\u001b[0m     \u001b[39m# GH 24704: use iloc to handle duplicate column names\u001b[39;00m\n\u001b[0;32m   5904\u001b[0m     \u001b[39m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\envs\\snowpark\\lib\\site-packages\\pandas\\core\\generic.py:5912\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5905\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m   5906\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m   5907\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m   5908\u001b[0m     ]\n\u001b[0;32m   5910\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5911\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 5912\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   5913\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5915\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\envs\\snowpark\\lib\\site-packages\\pandas\\core\\internals\\managers.py:419\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mastype\u001b[39m(\u001b[39mself\u001b[39m: T, dtype, copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m--> 419\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\envs\\snowpark\\lib\\site-packages\\pandas\\core\\internals\\managers.py:304\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    303\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    305\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    306\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\envs\\snowpark\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:580\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    578\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[1;32m--> 580\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    582\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    583\u001b[0m newb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\envs\\snowpark\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1292\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     dtype \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39mnumpy_dtype\n\u001b[0;32m   1291\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1292\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m   1293\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m   1294\u001b[0m     \u001b[39m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\envs\\snowpark\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1237\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m   1236\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1237\u001b[0m     values \u001b[39m=\u001b[39m astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m   1239\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\envs\\snowpark\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1148\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcannot astype a timedelta from [\u001b[39m\u001b[39m{\u001b[39;00marr\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m] to [\u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1147\u001b[0m \u001b[39melif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(arr\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mfloating) \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(dtype, np\u001b[39m.\u001b[39minteger):\n\u001b[1;32m-> 1148\u001b[0m     \u001b[39mreturn\u001b[39;00m astype_float_to_int_nansafe(arr, dtype, copy)\n\u001b[0;32m   1150\u001b[0m \u001b[39melif\u001b[39;00m is_object_dtype(arr\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m   1151\u001b[0m \n\u001b[0;32m   1152\u001b[0m     \u001b[39m# work around NumPy brokenness, #1987\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(dtype\u001b[39m.\u001b[39mtype, np\u001b[39m.\u001b[39minteger):\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\envs\\snowpark\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1193\u001b[0m, in \u001b[0;36mastype_float_to_int_nansafe\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m   1189\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[39mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(values)\u001b[39m.\u001b[39mall():\n\u001b[1;32m-> 1193\u001b[0m     \u001b[39mraise\u001b[39;00m IntCastingNaNError(\n\u001b[0;32m   1194\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1195\u001b[0m     )\n\u001b[0;32m   1196\u001b[0m \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[1;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "res.astype({'C_BIRTH_YEAR':'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['C_BIRTH_YEAR', 'CA_ZIP', 'CD_GENDER', 'CD_MARITAL_STATUS',\n",
       "       'CD_CREDIT_RATING', 'CD_EDUCATION_STATUS', 'CD_DEP_COUNT', 'PREDICTION',\n",
       "       'ACTUAL_SALES'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'C_BRITH_YEAR'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mC_BRITH_YEAR\u001b[39;49m\u001b[39m'\u001b[39;49m])[\u001b[39m'\u001b[39m\u001b[39mACTUAL_SALES\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msum()\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\envs\\snowpark\\lib\\site-packages\\pandas\\core\\frame.py:7721\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7716\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   7718\u001b[0m \u001b[39m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[0;32m   7719\u001b[0m \u001b[39m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   7720\u001b[0m \u001b[39m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> 7721\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   7722\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   7723\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[0;32m   7724\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   7725\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   7726\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[0;32m   7727\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   7728\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m   7729\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7730\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   7731\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   7732\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\envs\\snowpark\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[0;32m    883\u001b[0m         obj,\n\u001b[0;32m    884\u001b[0m         keys,\n\u001b[0;32m    885\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    886\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    887\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    888\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m    889\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[0;32m    890\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[0;32m    893\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[0;32m    894\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\envs\\snowpark\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    880\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 882\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    883\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'C_BRITH_YEAR'"
     ]
    }
   ],
   "source": [
    "res.groupby(['C_BRITH_YEAR'])['ACTUAL_SALES'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Value of 'values' is not the name of a column in 'data_frame'. Expected one of ['C_BIRTH_YEAR', 'CA_ZIP', 'CD_GENDER', 'CD_MARITAL_STATUS', 'CD_CREDIT_RATING', 'CD_EDUCATION_STATUS', 'CD_DEP_COUNT', 'PREDICTION', 'ACTUAL_SALES'] but received: ACXTUAL_SALES",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fig \u001b[39m=\u001b[39m px\u001b[39m.\u001b[39;49msunburst(res,\n\u001b[0;32m      2\u001b[0m                     path\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mC_BIRTH_YEAR\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mCA_ZIP\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mCD_GENDER\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mCD_MARITAL_STATUS\u001b[39;49m\u001b[39m'\u001b[39;49m],values\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mACXTUAL_SALES\u001b[39;49m\u001b[39m'\u001b[39;49m,color_discrete_sequence\u001b[39m=\u001b[39;49mpx\u001b[39m.\u001b[39;49mcolors\u001b[39m.\u001b[39;49mqualitative\u001b[39m.\u001b[39;49mPastel)\n\u001b[0;32m      3\u001b[0m fig\u001b[39m.\u001b[39mupdate_layout(width\u001b[39m=\u001b[39m\u001b[39m800\u001b[39m, \n\u001b[0;32m      4\u001b[0m                     height\u001b[39m=\u001b[39m\u001b[39m800\u001b[39m,\n\u001b[0;32m      5\u001b[0m                     )\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\envs\\snowpark\\lib\\site-packages\\plotly\\express\\_chart_types.py:1541\u001b[0m, in \u001b[0;36msunburst\u001b[1;34m(data_frame, names, values, parents, path, ids, color, color_continuous_scale, range_color, color_continuous_midpoint, color_discrete_sequence, color_discrete_map, hover_name, hover_data, custom_data, labels, title, template, width, height, branchvalues, maxdepth)\u001b[0m\n\u001b[0;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m branchvalues \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1540\u001b[0m     branchvalues \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtotal\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1541\u001b[0m \u001b[39mreturn\u001b[39;00m make_figure(\n\u001b[0;32m   1542\u001b[0m     args\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m(),\n\u001b[0;32m   1543\u001b[0m     constructor\u001b[39m=\u001b[39;49mgo\u001b[39m.\u001b[39;49mSunburst,\n\u001b[0;32m   1544\u001b[0m     trace_patch\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(branchvalues\u001b[39m=\u001b[39;49mbranchvalues, maxdepth\u001b[39m=\u001b[39;49mmaxdepth),\n\u001b[0;32m   1545\u001b[0m     layout_patch\u001b[39m=\u001b[39;49mlayout_patch,\n\u001b[0;32m   1546\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\envs\\snowpark\\lib\\site-packages\\plotly\\express\\_core.py:1991\u001b[0m, in \u001b[0;36mmake_figure\u001b[1;34m(args, constructor, trace_patch, layout_patch)\u001b[0m\n\u001b[0;32m   1988\u001b[0m layout_patch \u001b[39m=\u001b[39m layout_patch \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m   1989\u001b[0m apply_default_cascade(args)\n\u001b[1;32m-> 1991\u001b[0m args \u001b[39m=\u001b[39m build_dataframe(args, constructor)\n\u001b[0;32m   1992\u001b[0m \u001b[39mif\u001b[39;00m constructor \u001b[39min\u001b[39;00m [go\u001b[39m.\u001b[39mTreemap, go\u001b[39m.\u001b[39mSunburst, go\u001b[39m.\u001b[39mIcicle] \u001b[39mand\u001b[39;00m args[\u001b[39m\"\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1993\u001b[0m     args \u001b[39m=\u001b[39m process_dataframe_hierarchy(args)\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\envs\\snowpark\\lib\\site-packages\\plotly\\express\\_core.py:1406\u001b[0m, in \u001b[0;36mbuild_dataframe\u001b[1;34m(args, constructor)\u001b[0m\n\u001b[0;32m   1403\u001b[0m     args[\u001b[39m\"\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m \u001b[39m# now that things have been prepped, we do the systematic rewriting of `args`\u001b[39;00m\n\u001b[1;32m-> 1406\u001b[0m df_output, wide_id_vars \u001b[39m=\u001b[39m process_args_into_dataframe(\n\u001b[0;32m   1407\u001b[0m     args, wide_mode, var_name, value_name\n\u001b[0;32m   1408\u001b[0m )\n\u001b[0;32m   1410\u001b[0m \u001b[39m# now that `df_output` exists and `args` contains only references, we complete\u001b[39;00m\n\u001b[0;32m   1411\u001b[0m \u001b[39m# the special-case and wide-mode handling by further rewriting args and/or mutating\u001b[39;00m\n\u001b[0;32m   1412\u001b[0m \u001b[39m# df_output\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m count_name \u001b[39m=\u001b[39m _escape_col_name(df_output, \u001b[39m\"\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m\"\u001b[39m, [var_name, value_name])\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\envs\\snowpark\\lib\\site-packages\\plotly\\express\\_core.py:1208\u001b[0m, in \u001b[0;36mprocess_args_into_dataframe\u001b[1;34m(args, wide_mode, var_name, value_name)\u001b[0m\n\u001b[0;32m   1206\u001b[0m         \u001b[39mif\u001b[39;00m argument \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1207\u001b[0m             err_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m To use the index, pass it in directly as `df.index`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1208\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err_msg)\n\u001b[0;32m   1209\u001b[0m \u001b[39melif\u001b[39;00m length \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(df_input[argument]) \u001b[39m!=\u001b[39m length:\n\u001b[0;32m   1210\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1211\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAll arguments should have the same length. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1212\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe length of column argument `df[\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m]` is \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, whereas the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1219\u001b[0m         )\n\u001b[0;32m   1220\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Value of 'values' is not the name of a column in 'data_frame'. Expected one of ['C_BIRTH_YEAR', 'CA_ZIP', 'CD_GENDER', 'CD_MARITAL_STATUS', 'CD_CREDIT_RATING', 'CD_EDUCATION_STATUS', 'CD_DEP_COUNT', 'PREDICTION', 'ACTUAL_SALES'] but received: ACXTUAL_SALES"
     ]
    }
   ],
   "source": [
    "fig = px.sunburst(res,\n",
    "                    path=['C_BIRTH_YEAR', 'CA_ZIP', 'CD_GENDER', 'CD_MARITAL_STATUS'],values='ACXTUAL_SALES',color_discrete_sequence=px.colors.qualitative.Pastel)\n",
    "fig.update_layout(width=800, \n",
    "                    height=800,\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('snowpark_xgboost_tpc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "353961104846001ffa111d7d98923933ef13c251c8e9b3ebc563f652eb6b45f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
